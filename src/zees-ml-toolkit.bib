@online{achievedflops,
  title = {Achieved {{FLOPs}}},
  url = {https://docs.nvidia.com/gameworks/content/developertools/desktop/analysis/report/cudaexperiments/kernellevel/achievedflops.htm},
  urldate = {2023-11-14},
  abstract = {Measuring floating point operations per second is a common metric for comparing different algorithms, variants in implementation, or changes in the compute device. While optimizing kernel code its primary value is to provide an estimate of how close an implementation comes to the theoretical arithmetic peak performance of the target device. For that it can be used to track the progress of optimizing a kernel's performance; even though the metric itself provides limited insight to what might cause low performance.},
  organization = {{NVIDIA Nsight Visual Studio Edition}},
  file = {/Users/zee/Zotero/storage/KCD6WXXU/achievedflops.html}
}

@online{definitionneural,
  title = {Definition of {{Neural Network}} - {{Gartner Information Technology Glossary}}},
  url = {https://www.gartner.com/en/information-technology/glossary/neural-net-or-neural-network},
  urldate = {2023-11-14},
  abstract = {A neural network is a type of data processing, inspired by biological neurons, that converts between complex objects (such as audio and video) and tokens suitable for conventional data processing.},
  langid = {english},
  organization = {{Gartner}},
  file = {/Users/zee/Zotero/storage/J38CP3DB/neural-net-or-neural-network.html}
}

@article{hopfield:neuralnetworks:1982,
  title = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities.},
  author = {Hopfield, J J},
  date = {1982-04},
  journaltitle = {Proc Natl Acad Sci U S A},
  volume = {79},
  number = {8},
  eprint = {6953413},
  eprinttype = {pmid},
  pages = {2554--2558},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238/},
  urldate = {2023-11-14},
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  pmcid = {PMC346238},
  file = {/Users/zee/Zotero/storage/RS2PBHNQ/Hopfield - 1982 - Neural networks and physical systems with emergent.pdf}
}

@inproceedings{jang:neuralnetwork:2008,
  title = {Neural {{Network Implementation Using CUDA}} and {{OpenMP}}},
  booktitle = {2008 {{Digital Image Computing}}: {{Techniques}} and {{Applications}}},
  author = {Jang, Honghoon and Park, Anjin and Jung, Keechul},
  date = {2008-12},
  pages = {155--161},
  doi = {10.1109/DICTA.2008.82},
  url = {https://ieeexplore.ieee.org/abstract/document/4700015},
  urldate = {2023-11-14},
  abstract = {Many algorithms for image processing and pattern recognition have recently been implemented on GPU (graphic processing unit) for faster computational times. However, the implementation using GPU encounters two problems. First, the programmer should master the fundamentals of the graphics shading languages that require the prior knowledge on computer graphics. Second, in a job which needs much cooperation between CPU and GPU, which is usual in image processings and pattern recognitions contrary to the graphics area, CPU should generate raw feature data for GPU processing as much as possible to effectively utilize GPU performance. This paper proposes more quick and efficient implementation of neural networks on both GPU and multi-core CPU. We use CUDA (compute unified device architecture) that can be easily programmed due to its simple C language-like style instead of GPU to solve the first problem. Moreover, OpenMP (Open Multi-Processing) is used to concurrently process multiple data with single instruction on multi-core CPU, which results ineffectively utilizing the memories of GPU. In the experiments, we implemented neural networks-based text detection system using the proposed architecture, and the computational times showed about 15 times faster than implementation using CPU and about 4 times faster than implementation on only GPU without OpenMP.},
  eventtitle = {2008 {{Digital Image Computing}}: {{Techniques}} and {{Applications}}},
  file = {/Users/zee/Zotero/storage/WFYIYMZL/Jang et al. - 2008 - Neural Network Implementation Using CUDA and OpenM.pdf;/Users/zee/Zotero/storage/BKRFD2FS/4700015.html}
}

@online{newpascal:2016,
  title = {New {{Pascal GPUs Accelerate Inference}} in the {{Data Center}}},
  date = {2016-09-13T03:01+00:00},
  url = {https://developer.nvidia.com/blog/new-pascal-gpus-accelerate-inference-in-the-data-center/},
  urldate = {2023-11-14},
  abstract = {The new Tesla P4 and P40 accelerators are designed to meet the challenges of the modern data center, including efficient deep learning inference.},
  langid = {american},
  organization = {{NVIDIA Technical Blog}}
}

@online{welcomeaws,
  title = {Welcome to {{AWS Neuron}} â€” {{AWS Neuron Documentation}}},
  url = {https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html},
  urldate = {2023-11-14},
  file = {/Users/zee/Zotero/storage/7RYJCIRK/index.html}
}

@online{xlaoptimizing,
  title = {{{XLA}}: {{Optimizing Compiler}} for {{Machine Learning}}},
  shorttitle = {{{XLA}}},
  url = {https://www.tensorflow.org/xla},
  urldate = {2023-11-14},
  abstract = {XLA is a compiler-based linear algebra execution engine.},
  langid = {english},
  organization = {{TensorFlow}},
  file = {/Users/zee/Zotero/storage/G2ZST7AB/xla.html}
}
